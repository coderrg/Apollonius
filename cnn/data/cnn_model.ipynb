{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from torchvision.transforms import ToTensor \n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pickle\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, num_images=-1):\n",
    "    images = []\n",
    "    labels = []\n",
    "    counter = 0 \n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if counter >= num_images and num_images != -1:\n",
    "            break\n",
    "        img = cv2.imread(os.path.join(folder,filename), 0)\n",
    "        try: \n",
    "            label = int(filename.split(\"_\")[2])\n",
    "            for i in range(len(img)):\n",
    "                for j in range(len(img[i])):\n",
    "                    img[i][j] = int(img[i][j] > 0.5 * 255)\n",
    "            if (img is not None):\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                filenames.append(filename)\n",
    "            counter += 1\n",
    "        except:\n",
    "            print(filename)\n",
    "    return images, labels, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "def get_data(folder, num_images=-1):\n",
    "    images, labels, _ = load_images_from_folder(folder, num_images)\n",
    "    print(images[0][0:10, 0:10])\n",
    "    X_t, X_test, y_t, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size=0.25, random_state=1038)\n",
    "    X_train = T.tensor(X_train)\n",
    "    y_train = T.tensor(y_train)\n",
    "    X_val = T.tensor(X_val)\n",
    "    y_val = T.tensor(y_val)\n",
    "    X_test = T.tensor(X_test)\n",
    "    y_test = T.tensor(y_test)\n",
    "\n",
    "    y_train = y_train.type(T.LongTensor)\n",
    "    y_val = y_val.type(T.LongTensor)\n",
    "    y_test = y_test.type(T.LongTensor)\n",
    "    train_dataset = T.utils.data.TensorDataset(X_train, y_train)\n",
    "    val_dataset = T.utils.data.TensorDataset(X_val, y_val)\n",
    "    test_dataset = T.utils.data.TensorDataset(X_test, y_test)\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "train_dataset, val_dataset, test_dataset = get_data(\"endpt_dataset/window_images\")\n",
    "with open('train_endptdataset.pickle', 'wb') as f:\n",
    "    pickle.dump(train_dataset, f)\n",
    "with open('val_endptdataset.pickle', 'wb') as f:\n",
    "    pickle.dump(val_dataset, f)\n",
    "with open('test_endptdataset.pickle', 'wb') as f:\n",
    "    pickle.dump(test_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, lr, epochs, input_dims, batch_size, name, best_name, chkpt_dir, dataset_prefix, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.chkpt_dir = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.chkpt_dir, name)\n",
    "        self.best_checkpoint_file = os.path.join(self.chkpt_dir, best_name)\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.input_dims = input_dims\n",
    "        self.batch_size = batch_size \n",
    "        self.num_classes = num_classes\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "        self.skipped_points = []\n",
    "        self.val_history = [0, 0, 0]\n",
    "        self.device = T.device(\"cpu\")\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.conv6 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        fc_dims = self.calc_fc_dims()\n",
    "        self.fc1 = nn.Linear(fc_dims, 32)\n",
    "        self.fc2 = nn.Linear(32, 16) \n",
    "        self.fc3 = nn.Linear(16, self.num_classes)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr) # the self.parameters() comes from nn.Module \n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss() # since we have more than 2 classes cross entropy is best otherwise with 2 classes we might be able to use binary loss\n",
    "        \n",
    "        self.to(self.device)\n",
    "        self.get_data(\"train\" + dataset_prefix, \"val\" + dataset_prefix, \"test\" + dataset_prefix)\n",
    "\n",
    "    def calc_fc_dims(self):\n",
    "        batch_data = T.zeros((1, 1, 25, 25)) # 4-tensor of 0s and we plug it into the layer and see what comes out \n",
    "        batch_data = self.conv1(batch_data)\n",
    "        # batch_data = self.bn1(batch_data) # batch norm layer does not change dimesnionality\n",
    "        batch_data = self.conv2(batch_data)\n",
    "        # batch_data = self.bn2(batch_data)\n",
    "        batch_data = self.conv3(batch_data)\n",
    "        # batch_data = self.bn3(batch_data)\n",
    "        batch_data = self.maxpool1(batch_data)\n",
    "        batch_data = self.conv4(batch_data)\n",
    "        batch_data = self.conv5(batch_data)\n",
    "        batch_data = self.conv6(batch_data)\n",
    "        batch_data = self.maxpool2(batch_data)\n",
    "\n",
    "        return int(np.prod(batch_data.size())) # this will give us the input dimesniosn \n",
    "\n",
    "    def forward(self, batch_data): # NOTE: we can kinda combine this with calc_fc_dims() \n",
    "        batch_data = T.tensor(batch_data).to(self.device) # lower case tensor() preserves the datatype while Tensor() changes the datatype to some default datatype \n",
    "        # we do a to(self.device) in order to make sure it is not a cuda tensor \n",
    "        try: \n",
    "            batch_data = T.reshape(batch_data, self.input_dims)\n",
    "        except:\n",
    "            pass\n",
    "        batch_data = batch_data.type(T.FloatTensor)\n",
    "#             print(batch_data.size(), batch_data.type(), batch_data)\n",
    "# \t\tprint(batch_data.type())\n",
    "        batch_data = self.conv1(batch_data)\n",
    "        batch_data = self.bn1(batch_data) # debate about whether to do batch norm before or after relu but this works fine for this one especially since relu is a noncommutative operation with respect to things like addition\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.conv2(batch_data)\n",
    "        batch_data = self.bn2(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.conv3(batch_data)\n",
    "        batch_data = self.bn3(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.maxpool1(batch_data)\n",
    "\n",
    "        batch_data = self.conv4(batch_data)\n",
    "        batch_data = self.bn4(batch_data)\n",
    "        batch_data = F.relu(batch_data) \n",
    "\n",
    "        batch_data = self.conv5(batch_data)\n",
    "        batch_data = self.bn5(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.conv6(batch_data)\n",
    "        batch_data = self.bn6(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.maxpool2(batch_data)\n",
    "\n",
    "        batch_data = batch_data.view(batch_data.size()[0], -1)\n",
    "\n",
    "        batch_data = self.fc1(batch_data)\n",
    "        batch_data = self.fc2(batch_data)\n",
    "        classes = self.fc3(batch_data)\n",
    "        # note that we are not doing another activation after this since the linear cross entropy loss performs a softmax activation on it already \n",
    "\n",
    "        return classes\n",
    "        \n",
    "    def get_data(self, train_filename, val_filename, test_filename):\n",
    "\n",
    "        with open(train_filename, 'rb') as f:\n",
    "            train_dataset = pickle.load(f)\n",
    "        with open(val_filename, 'rb') as f:\n",
    "            val_dataset = pickle.load(f)\n",
    "        with open(test_filename, 'rb') as f:\n",
    "            test_dataset = pickle.load(f)\n",
    "        \n",
    "# \t\tmnist_train_data = MNIST(\"mnist\", train=True, download=True, \n",
    "# \t\t\t\t\t\t\t\ttransform=ToTensor())\n",
    "        self.train_data_loader = T.utils.data.DataLoader(train_dataset, \n",
    "                                    batch_size=self.batch_size, shuffle=True, # always want to shuffle the in case it was not preshuffled so that we get actual learning \n",
    "                                    num_workers=3) # this part is just so that the computer can split up the task so make it less than 4 for a mac \n",
    "        self.val_data_loader = T.utils.data.DataLoader(val_dataset, \n",
    "                                    batch_size=1, shuffle=True, \n",
    "                                    num_workers=3)\n",
    "# \t\tmnist_test_data = MNIST(\"mnist\", train=False, download=True, \n",
    "# \t\t\t\t\t\t\t\ttransform=ToTensor())\n",
    "        self.test_data_loader = T.utils.data.DataLoader(test_dataset, \n",
    "                                    batch_size=self.batch_size, shuffle=True, # always want to shuffle the in case it was not preshuffled so that we get actual learning \n",
    "                                    num_workers=3) \n",
    "\n",
    "    def _val(self):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for j, (input, label) in enumerate(self.val_data_loader): \n",
    "            input = T.reshape(input, (1,1,25,25))\n",
    "#             print(input.type())\n",
    "            prediction = self.forward(input)\n",
    "            prediction = F.softmax(prediction, dim=1)\n",
    "            classes = T.argmax(prediction, dim=1)\n",
    "            y_pred.append(classes.item())\n",
    "            y_true.append(label.item())\n",
    "#         print(\"y_true is: \\n\", y_true[:10], \"\\n ---------------------------- \\n \", \"y_pred is: \\n\", y_pred[:10])\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "        print(\"The confusion matrix is: \\n\", conf_matrix)\n",
    "        self.val_history.append(f1_score(y_true, y_pred, zero_division=1))\n",
    "        return conf_matrix[0][0] + conf_matrix[1][1]/(np.sum(conf_matrix))\n",
    "        \n",
    "        \n",
    "    def _train(self):\n",
    "        self.train() # this is important if you are using pytorch with batch norm (it only switches the neural net to a train mode where it remembers the batch norm statistics for training thus only do this with batch norm)\n",
    "        for i in range(self.epochs): # iteration over the full dataset (we have 60,000 in training set, 10,000 in the test set) so we want to iterate over it many many times \n",
    "            ep_loss = 0\n",
    "            ep_acc = [] # this is epoch accuracy \n",
    "            counter = 0\n",
    "            for j, (input, label) in enumerate(self.train_data_loader): # the default format is an integer and a tuple with an input and an actual label\n",
    "#                 print(input.type())\n",
    "                self.optimizer.zero_grad() # remember to always zero the gradient before your training as otherwise it will remember stuff from the last cycle \n",
    "                label = label.to(self.device)\n",
    "# \t\t\t\tprint(input.size(), label)\n",
    "# \t\t\t\tprint(input.type(), label.type())\n",
    "                if input.size()[0] != 8:\n",
    "                    print(\"I am passing\")\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    prediction = self.forward(input)\n",
    "                    loss = self.loss(prediction, label)\n",
    "                    prediction = F.softmax(prediction, dim=1) # the softmax is so that we get a probabilities over the classes \n",
    "                    classes = T.argmax(prediction, dim=1)\n",
    "                    wrong = T.where(classes != label, T.tensor([1.]).to(self.device), T.tensor([0.]).to(self.device)) # this looks at when the labels are not correct and marsk those with a 1\n",
    "                    acc = 1 - T.sum(wrong) / self.batch_size\n",
    "                    \n",
    "                    ep_acc.append(acc.item()) # acc is a tensor so we look at the item in the tensor \n",
    "                    self.acc_history.append(acc.item())\n",
    "                    ep_loss += loss.item()\n",
    "                    loss.backward() # this calculates the gradient and is VERY IMPORTANT \n",
    "                    self.optimizer.step() # this uses the optimizer to adjust the weights ALSO VERY IMPORTANT \n",
    "\n",
    "                    if (j % 1000 == 0):\n",
    "                        print(\"Epoch \", i, \"Data Point \", j, \"total loss %.3f\" % ep_loss, \"accuracy %.3f\" % np.mean(ep_acc))\n",
    "\n",
    "            self._val()\n",
    "            print(\"Finished Epoch \", i, \"total loss %.3f\" % ep_loss, \"accuracy %.3f\" % np.mean(ep_acc), \n",
    "                  \"validation f1 %.3f\" % self.val_history[-1])\n",
    "            print(self.val_history)\n",
    "            self.skipped_points.append(counter)\n",
    "            if counter:\n",
    "                print(\"Number of skipped points is \", counter)\n",
    "            self.loss_history.append(ep_loss)\n",
    "#             if (i % 1 == 0):\n",
    "            if self.val_history[-1] >= self.val_history[-2]:\n",
    "                self.save_checkpoint(best=self.val_history[-1] == max(self.val_history))\n",
    "#             if self.val_history[-1] < self.val_history[-2] and self.val_history[-2] < self.val_history[-3]:\n",
    "#                 break\n",
    "    def _test(self):\n",
    "        \n",
    "        # self.test() # this is important if you are using pytorch with batch norm so now we can run it in test mode\n",
    "        ep_loss = 0\n",
    "        ep_acc = [] # this is epoch accuracy \n",
    "        counter = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for j, (input, label) in enumerate(self.test_data_loader): # the default format is an integer and a tuple with an input and an actual label\n",
    "            label = label.to(self.device)\n",
    "            if input.size()[0] != 8:\n",
    "#                 print(\"I am passing\")\n",
    "                counter += 1\n",
    "            else:  \n",
    "                prediction = self.forward(input)\n",
    "                loss = self.loss(prediction, label)\n",
    "                prediction = F.softmax(prediction, dim=1) # the softmax is so that we get a probabilities over the classes \n",
    "                classes = T.argmax(prediction, dim=1)\n",
    "                wrong = T.where(classes != label, T.tensor([1.]).to(self.device), T.tensor([0.]).to(self.device)) # this looks at when the labels are not correct and marsk those with a 1\n",
    "                acc = 1 - T.sum(wrong) / self.batch_size\n",
    "                for i in range(self.batch_size):\n",
    "                    y_true.append(label[i].item())\n",
    "                    y_pred.append(classes[i].item())\n",
    "                ep_acc.append(acc.item()) # acc is a tensor so we look at the item in the tensor \n",
    "                ep_loss += loss.item()\n",
    "        print(\"The confusion matrix is: \\n\", confusion_matrix(y_true, y_pred, labels=[0,1]))\n",
    "        print(f\"The f1 score is {f1_score(y_true, y_pred, zero_division=1)}\")\n",
    "\n",
    "        print(\"Total loss %.3f\" % ep_loss, \"accuracy %.3f\" % np.mean(ep_acc))\n",
    "        if counter:\n",
    "            print(\"Number of skipped points is \", counter)\n",
    "        \n",
    "        return ep_acc\n",
    "\n",
    "    def save_checkpoint(self, filename=None, best=False):\n",
    "        filename = self.checkpoint_file if filename is None else filename\n",
    "        print('... saving checkpoint ...')\n",
    "        T.save(self.state_dict(), filename)\n",
    "        if best:\n",
    "            T.save(self.state_dict(), self.best_checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self, filename=None):\n",
    "        filename = self.best_checkpoint_file if filename is None else filename\n",
    "        print('... loading checkpoint ...')\n",
    "        self.load_state_dict(T.load(filename))\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CNN(lr=0.001, input_dims=(8,1,25,25), batch_size=8, epochs=20, name='CNN_V5', best_name='CNN_best_V5', chkpt_dir='cnn_history/endpt_cnn', dataset_prefix = \"_endptdataset.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13787 379852 0.036295715173278016\n"
     ]
    }
   ],
   "source": [
    "positive_counter = 0\n",
    "counter = 0\n",
    "for filename in os.listdir(\"endpt_dataset/window_images\"):\n",
    "    positive_counter += int(filename.split(\"_\")[2])\n",
    "    counter += 1\n",
    "print(positive_counter, counter, positive_counter/counter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidhartkrishnan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Data Point  0 total loss 0.678 accuracy 0.750\n",
      "Epoch  0 Data Point  1000 total loss 129.276 accuracy 0.963\n",
      "Epoch  0 Data Point  2000 total loss 230.775 accuracy 0.966\n",
      "Epoch  0 Data Point  3000 total loss 313.325 accuracy 0.968\n",
      "Epoch  0 Data Point  4000 total loss 371.199 accuracy 0.972\n",
      "Epoch  0 Data Point  5000 total loss 423.802 accuracy 0.974\n",
      "Epoch  0 Data Point  6000 total loss 471.928 accuracy 0.976\n",
      "Epoch  0 Data Point  7000 total loss 527.299 accuracy 0.977\n",
      "Epoch  0 Data Point  8000 total loss 573.084 accuracy 0.978\n",
      "Epoch  0 Data Point  9000 total loss 614.376 accuracy 0.979\n",
      "Epoch  0 Data Point  10000 total loss 662.854 accuracy 0.980\n",
      "Epoch  0 Data Point  11000 total loss 700.621 accuracy 0.980\n",
      "Epoch  0 Data Point  12000 total loss 739.191 accuracy 0.981\n",
      "Epoch  0 Data Point  13000 total loss 771.975 accuracy 0.982\n",
      "Epoch  0 Data Point  14000 total loss 804.808 accuracy 0.982\n",
      "Epoch  0 Data Point  15000 total loss 838.009 accuracy 0.983\n",
      "Epoch  0 Data Point  16000 total loss 875.005 accuracy 0.983\n",
      "Epoch  0 Data Point  17000 total loss 914.412 accuracy 0.983\n",
      "Epoch  0 Data Point  18000 total loss 947.634 accuracy 0.983\n",
      "Epoch  0 Data Point  19000 total loss 977.233 accuracy 0.984\n",
      "Epoch  0 Data Point  20000 total loss 1009.518 accuracy 0.984\n",
      "Epoch  0 Data Point  21000 total loss 1044.382 accuracy 0.984\n",
      "Epoch  0 Data Point  22000 total loss 1074.205 accuracy 0.984\n",
      "Epoch  0 Data Point  23000 total loss 1102.578 accuracy 0.985\n",
      "Epoch  0 Data Point  24000 total loss 1132.318 accuracy 0.985\n",
      "Epoch  0 Data Point  25000 total loss 1164.415 accuracy 0.985\n",
      "Epoch  0 Data Point  26000 total loss 1196.287 accuracy 0.985\n",
      "Epoch  0 Data Point  27000 total loss 1222.337 accuracy 0.985\n",
      "Epoch  0 Data Point  28000 total loss 1247.866 accuracy 0.986\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73218    29]\n",
      " [ 2570   154]]\n",
      "Finished Epoch  0 total loss 1258.748 accuracy 0.986 validation f1 0.106\n",
      "[0, 0, 0, 0.10595115239078087]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  1 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  1 Data Point  1000 total loss 26.142 accuracy 0.991\n",
      "Epoch  1 Data Point  2000 total loss 62.725 accuracy 0.990\n",
      "Epoch  1 Data Point  3000 total loss 96.671 accuracy 0.989\n",
      "Epoch  1 Data Point  4000 total loss 124.593 accuracy 0.990\n",
      "Epoch  1 Data Point  5000 total loss 144.867 accuracy 0.990\n",
      "Epoch  1 Data Point  6000 total loss 166.696 accuracy 0.991\n",
      "Epoch  1 Data Point  7000 total loss 198.155 accuracy 0.990\n",
      "Epoch  1 Data Point  8000 total loss 224.146 accuracy 0.990\n",
      "Epoch  1 Data Point  9000 total loss 250.181 accuracy 0.990\n",
      "Epoch  1 Data Point  10000 total loss 274.256 accuracy 0.991\n",
      "Epoch  1 Data Point  11000 total loss 301.528 accuracy 0.991\n",
      "Epoch  1 Data Point  12000 total loss 328.521 accuracy 0.991\n",
      "Epoch  1 Data Point  13000 total loss 353.249 accuracy 0.990\n",
      "Epoch  1 Data Point  14000 total loss 380.374 accuracy 0.990\n",
      "Epoch  1 Data Point  15000 total loss 405.460 accuracy 0.991\n",
      "Epoch  1 Data Point  16000 total loss 433.438 accuracy 0.991\n",
      "Epoch  1 Data Point  17000 total loss 457.084 accuracy 0.991\n",
      "Epoch  1 Data Point  18000 total loss 477.252 accuracy 0.991\n",
      "Epoch  1 Data Point  19000 total loss 501.814 accuracy 0.991\n",
      "Epoch  1 Data Point  20000 total loss 524.841 accuracy 0.991\n",
      "Epoch  1 Data Point  21000 total loss 550.176 accuracy 0.991\n",
      "Epoch  1 Data Point  22000 total loss 573.773 accuracy 0.991\n",
      "Epoch  1 Data Point  23000 total loss 601.644 accuracy 0.991\n",
      "Epoch  1 Data Point  24000 total loss 625.893 accuracy 0.991\n",
      "Epoch  1 Data Point  25000 total loss 649.818 accuracy 0.991\n",
      "Epoch  1 Data Point  26000 total loss 673.891 accuracy 0.991\n",
      "Epoch  1 Data Point  27000 total loss 701.047 accuracy 0.991\n",
      "Epoch  1 Data Point  28000 total loss 727.073 accuracy 0.991\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73139   108]\n",
      " [ 2320   404]]\n",
      "Finished Epoch  1 total loss 736.895 accuracy 0.991 validation f1 0.250\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  2 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  2 Data Point  1000 total loss 18.731 accuracy 0.993\n",
      "Epoch  2 Data Point  2000 total loss 41.294 accuracy 0.993\n",
      "Epoch  2 Data Point  3000 total loss 63.307 accuracy 0.992\n",
      "Epoch  2 Data Point  4000 total loss 86.429 accuracy 0.992\n",
      "Epoch  2 Data Point  5000 total loss 108.539 accuracy 0.992\n",
      "Epoch  2 Data Point  6000 total loss 130.129 accuracy 0.992\n",
      "Epoch  2 Data Point  7000 total loss 152.852 accuracy 0.992\n",
      "Epoch  2 Data Point  8000 total loss 174.873 accuracy 0.992\n",
      "Epoch  2 Data Point  9000 total loss 195.635 accuracy 0.992\n",
      "Epoch  2 Data Point  10000 total loss 218.635 accuracy 0.992\n",
      "Epoch  2 Data Point  11000 total loss 240.223 accuracy 0.992\n",
      "Epoch  2 Data Point  12000 total loss 265.048 accuracy 0.992\n",
      "Epoch  2 Data Point  13000 total loss 285.843 accuracy 0.992\n",
      "Epoch  2 Data Point  14000 total loss 308.680 accuracy 0.992\n",
      "Epoch  2 Data Point  15000 total loss 336.003 accuracy 0.992\n",
      "Epoch  2 Data Point  16000 total loss 361.810 accuracy 0.992\n",
      "Epoch  2 Data Point  17000 total loss 385.411 accuracy 0.992\n",
      "Epoch  2 Data Point  18000 total loss 407.643 accuracy 0.992\n",
      "Epoch  2 Data Point  19000 total loss 428.507 accuracy 0.992\n",
      "Epoch  2 Data Point  20000 total loss 447.638 accuracy 0.992\n",
      "Epoch  2 Data Point  21000 total loss 473.232 accuracy 0.992\n",
      "Epoch  2 Data Point  22000 total loss 495.504 accuracy 0.992\n",
      "Epoch  2 Data Point  23000 total loss 517.997 accuracy 0.992\n",
      "Epoch  2 Data Point  24000 total loss 539.813 accuracy 0.992\n",
      "Epoch  2 Data Point  25000 total loss 560.986 accuracy 0.992\n",
      "Epoch  2 Data Point  26000 total loss 587.367 accuracy 0.992\n",
      "Epoch  2 Data Point  27000 total loss 605.314 accuracy 0.992\n",
      "Epoch  2 Data Point  28000 total loss 626.322 accuracy 0.992\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73202    45]\n",
      " [ 2458   266]]\n",
      "Finished Epoch  2 total loss 638.113 accuracy 0.992 validation f1 0.175\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826]\n",
      "Number of skipped points is  1\n",
      "Epoch  3 Data Point  0 total loss 0.001 accuracy 1.000\n",
      "Epoch  3 Data Point  1000 total loss 20.485 accuracy 0.993\n",
      "Epoch  3 Data Point  2000 total loss 40.591 accuracy 0.994\n",
      "Epoch  3 Data Point  3000 total loss 63.557 accuracy 0.993\n",
      "Epoch  3 Data Point  4000 total loss 85.270 accuracy 0.993\n",
      "Epoch  3 Data Point  5000 total loss 102.359 accuracy 0.993\n",
      "Epoch  3 Data Point  6000 total loss 123.954 accuracy 0.993\n",
      "Epoch  3 Data Point  7000 total loss 141.758 accuracy 0.993\n",
      "Epoch  3 Data Point  8000 total loss 159.550 accuracy 0.993\n",
      "Epoch  3 Data Point  9000 total loss 180.474 accuracy 0.993\n",
      "Epoch  3 Data Point  10000 total loss 201.574 accuracy 0.993\n",
      "Epoch  3 Data Point  11000 total loss 222.926 accuracy 0.993\n",
      "Epoch  3 Data Point  12000 total loss 243.166 accuracy 0.993\n",
      "Epoch  3 Data Point  13000 total loss 262.380 accuracy 0.993\n",
      "Epoch  3 Data Point  14000 total loss 283.213 accuracy 0.993\n",
      "Epoch  3 Data Point  15000 total loss 306.796 accuracy 0.993\n",
      "Epoch  3 Data Point  16000 total loss 327.143 accuracy 0.993\n",
      "Epoch  3 Data Point  17000 total loss 344.975 accuracy 0.993\n",
      "Epoch  3 Data Point  18000 total loss 363.401 accuracy 0.993\n",
      "Epoch  3 Data Point  19000 total loss 388.161 accuracy 0.993\n",
      "Epoch  3 Data Point  20000 total loss 406.516 accuracy 0.993\n",
      "Epoch  3 Data Point  21000 total loss 426.592 accuracy 0.993\n",
      "Epoch  3 Data Point  22000 total loss 442.293 accuracy 0.993\n",
      "Epoch  3 Data Point  23000 total loss 461.624 accuracy 0.993\n",
      "Epoch  3 Data Point  24000 total loss 482.380 accuracy 0.993\n",
      "Epoch  3 Data Point  25000 total loss 502.482 accuracy 0.993\n",
      "Epoch  3 Data Point  26000 total loss 520.591 accuracy 0.993\n",
      "Epoch  3 Data Point  27000 total loss 538.971 accuracy 0.993\n",
      "Epoch  3 Data Point  28000 total loss 560.949 accuracy 0.993\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73231    16]\n",
      " [ 2592   132]]\n",
      "Finished Epoch  3 total loss 571.079 accuracy 0.993 validation f1 0.092\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064]\n",
      "Number of skipped points is  1\n",
      "Epoch  4 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  4 Data Point  1000 total loss 15.434 accuracy 0.995\n",
      "Epoch  4 Data Point  2000 total loss 32.288 accuracy 0.994\n",
      "Epoch  4 Data Point  3000 total loss 47.526 accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 Data Point  4000 total loss 66.681 accuracy 0.994\n",
      "Epoch  4 Data Point  5000 total loss 85.097 accuracy 0.994\n",
      "Epoch  4 Data Point  6000 total loss 102.928 accuracy 0.994\n",
      "Epoch  4 Data Point  7000 total loss 122.412 accuracy 0.994\n",
      "Epoch  4 Data Point  8000 total loss 139.302 accuracy 0.994\n",
      "Epoch  4 Data Point  9000 total loss 159.047 accuracy 0.994\n",
      "Epoch  4 Data Point  10000 total loss 177.315 accuracy 0.994\n",
      "Epoch  4 Data Point  11000 total loss 198.044 accuracy 0.994\n",
      "Epoch  4 Data Point  12000 total loss 218.852 accuracy 0.994\n",
      "Epoch  4 Data Point  13000 total loss 235.261 accuracy 0.994\n",
      "Epoch  4 Data Point  14000 total loss 250.489 accuracy 0.994\n",
      "Epoch  4 Data Point  15000 total loss 265.713 accuracy 0.994\n",
      "Epoch  4 Data Point  16000 total loss 285.952 accuracy 0.994\n",
      "Epoch  4 Data Point  17000 total loss 307.840 accuracy 0.994\n",
      "Epoch  4 Data Point  18000 total loss 325.835 accuracy 0.994\n",
      "Epoch  4 Data Point  19000 total loss 347.018 accuracy 0.994\n",
      "Epoch  4 Data Point  20000 total loss 365.921 accuracy 0.993\n",
      "Epoch  4 Data Point  21000 total loss 386.498 accuracy 0.993\n",
      "Epoch  4 Data Point  22000 total loss 405.752 accuracy 0.994\n",
      "Epoch  4 Data Point  23000 total loss 422.111 accuracy 0.994\n",
      "Epoch  4 Data Point  24000 total loss 443.206 accuracy 0.994\n",
      "Epoch  4 Data Point  25000 total loss 466.197 accuracy 0.993\n",
      "Epoch  4 Data Point  26000 total loss 482.800 accuracy 0.993\n",
      "Epoch  4 Data Point  27000 total loss 505.634 accuracy 0.993\n",
      "Epoch  4 Data Point  28000 total loss 521.184 accuracy 0.993\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73183    64]\n",
      " [ 2448   276]]\n",
      "Finished Epoch  4 total loss 529.717 accuracy 0.993 validation f1 0.180\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  5 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  5 Data Point  1000 total loss 18.739 accuracy 0.993\n",
      "Epoch  5 Data Point  2000 total loss 36.547 accuracy 0.993\n",
      "Epoch  5 Data Point  3000 total loss 52.295 accuracy 0.993\n",
      "Epoch  5 Data Point  4000 total loss 67.913 accuracy 0.994\n",
      "Epoch  5 Data Point  5000 total loss 86.627 accuracy 0.993\n",
      "Epoch  5 Data Point  6000 total loss 106.449 accuracy 0.993\n",
      "Epoch  5 Data Point  7000 total loss 126.684 accuracy 0.993\n",
      "Epoch  5 Data Point  8000 total loss 147.554 accuracy 0.993\n",
      "Epoch  5 Data Point  9000 total loss 162.809 accuracy 0.993\n",
      "Epoch  5 Data Point  10000 total loss 179.958 accuracy 0.993\n",
      "Epoch  5 Data Point  11000 total loss 195.556 accuracy 0.994\n",
      "Epoch  5 Data Point  12000 total loss 212.782 accuracy 0.994\n",
      "Epoch  5 Data Point  13000 total loss 232.299 accuracy 0.994\n",
      "Epoch  5 Data Point  14000 total loss 251.456 accuracy 0.994\n",
      "Epoch  5 Data Point  15000 total loss 266.889 accuracy 0.994\n",
      "Epoch  5 Data Point  16000 total loss 282.478 accuracy 0.994\n",
      "Epoch  5 Data Point  17000 total loss 297.358 accuracy 0.994\n",
      "Epoch  5 Data Point  18000 total loss 315.627 accuracy 0.994\n",
      "Epoch  5 Data Point  19000 total loss 331.829 accuracy 0.994\n",
      "Epoch  5 Data Point  20000 total loss 352.542 accuracy 0.994\n",
      "Epoch  5 Data Point  21000 total loss 369.762 accuracy 0.994\n",
      "Epoch  5 Data Point  22000 total loss 384.875 accuracy 0.994\n",
      "Epoch  5 Data Point  23000 total loss 398.631 accuracy 0.994\n",
      "Epoch  5 Data Point  24000 total loss 419.589 accuracy 0.994\n",
      "Epoch  5 Data Point  25000 total loss 437.279 accuracy 0.994\n",
      "Epoch  5 Data Point  26000 total loss 453.489 accuracy 0.994\n",
      "Epoch  5 Data Point  27000 total loss 472.279 accuracy 0.994\n",
      "Epoch  5 Data Point  28000 total loss 492.112 accuracy 0.994\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73166    81]\n",
      " [ 2325   399]]\n",
      "Finished Epoch  5 total loss 500.075 accuracy 0.994 validation f1 0.249\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  6 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  6 Data Point  1000 total loss 14.482 accuracy 0.994\n",
      "Epoch  6 Data Point  2000 total loss 29.813 accuracy 0.995\n",
      "Epoch  6 Data Point  3000 total loss 47.104 accuracy 0.994\n",
      "Epoch  6 Data Point  4000 total loss 61.138 accuracy 0.994\n",
      "Epoch  6 Data Point  5000 total loss 73.970 accuracy 0.994\n",
      "Epoch  6 Data Point  6000 total loss 93.489 accuracy 0.994\n",
      "Epoch  6 Data Point  7000 total loss 108.387 accuracy 0.994\n",
      "Epoch  6 Data Point  8000 total loss 128.366 accuracy 0.994\n",
      "Epoch  6 Data Point  9000 total loss 144.744 accuracy 0.994\n",
      "Epoch  6 Data Point  10000 total loss 161.111 accuracy 0.994\n",
      "Epoch  6 Data Point  11000 total loss 179.143 accuracy 0.994\n",
      "Epoch  6 Data Point  12000 total loss 194.932 accuracy 0.994\n",
      "Epoch  6 Data Point  13000 total loss 209.901 accuracy 0.994\n",
      "Epoch  6 Data Point  14000 total loss 227.872 accuracy 0.994\n",
      "Epoch  6 Data Point  15000 total loss 243.156 accuracy 0.994\n",
      "Epoch  6 Data Point  16000 total loss 263.099 accuracy 0.994\n",
      "Epoch  6 Data Point  17000 total loss 278.967 accuracy 0.994\n",
      "Epoch  6 Data Point  18000 total loss 296.314 accuracy 0.994\n",
      "Epoch  6 Data Point  19000 total loss 312.770 accuracy 0.994\n",
      "Epoch  6 Data Point  20000 total loss 327.259 accuracy 0.994\n",
      "Epoch  6 Data Point  21000 total loss 342.041 accuracy 0.994\n",
      "Epoch  6 Data Point  22000 total loss 356.916 accuracy 0.994\n",
      "Epoch  6 Data Point  23000 total loss 371.112 accuracy 0.994\n",
      "Epoch  6 Data Point  24000 total loss 386.541 accuracy 0.994\n",
      "Epoch  6 Data Point  25000 total loss 401.131 accuracy 0.994\n",
      "Epoch  6 Data Point  26000 total loss 422.394 accuracy 0.994\n",
      "Epoch  6 Data Point  27000 total loss 441.691 accuracy 0.994\n",
      "Epoch  6 Data Point  28000 total loss 457.924 accuracy 0.994\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73149    98]\n",
      " [ 2247   477]]\n",
      "Finished Epoch  6 total loss 466.116 accuracy 0.994 validation f1 0.289\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  7 Data Point  0 total loss 0.005 accuracy 1.000\n",
      "Epoch  7 Data Point  1000 total loss 14.762 accuracy 0.995\n",
      "Epoch  7 Data Point  2000 total loss 31.678 accuracy 0.995\n",
      "Epoch  7 Data Point  3000 total loss 45.772 accuracy 0.995\n",
      "Epoch  7 Data Point  4000 total loss 60.888 accuracy 0.995\n",
      "Epoch  7 Data Point  5000 total loss 75.771 accuracy 0.995\n",
      "Epoch  7 Data Point  6000 total loss 92.608 accuracy 0.995\n",
      "Epoch  7 Data Point  7000 total loss 108.976 accuracy 0.995\n",
      "Epoch  7 Data Point  8000 total loss 124.345 accuracy 0.995\n",
      "Epoch  7 Data Point  9000 total loss 139.327 accuracy 0.995\n",
      "Epoch  7 Data Point  10000 total loss 155.477 accuracy 0.995\n",
      "Epoch  7 Data Point  11000 total loss 168.950 accuracy 0.995\n",
      "Epoch  7 Data Point  12000 total loss 185.907 accuracy 0.995\n",
      "Epoch  7 Data Point  13000 total loss 202.193 accuracy 0.995\n",
      "Epoch  7 Data Point  14000 total loss 218.355 accuracy 0.995\n",
      "Epoch  7 Data Point  15000 total loss 234.291 accuracy 0.995\n",
      "Epoch  7 Data Point  16000 total loss 252.148 accuracy 0.995\n",
      "Epoch  7 Data Point  17000 total loss 266.850 accuracy 0.995\n",
      "Epoch  7 Data Point  18000 total loss 281.230 accuracy 0.995\n",
      "Epoch  7 Data Point  19000 total loss 295.023 accuracy 0.995\n",
      "Epoch  7 Data Point  20000 total loss 309.634 accuracy 0.995\n",
      "Epoch  7 Data Point  21000 total loss 324.094 accuracy 0.995\n",
      "Epoch  7 Data Point  22000 total loss 339.038 accuracy 0.995\n",
      "Epoch  7 Data Point  23000 total loss 354.849 accuracy 0.995\n",
      "Epoch  7 Data Point  24000 total loss 369.645 accuracy 0.995\n",
      "Epoch  7 Data Point  25000 total loss 385.713 accuracy 0.995\n",
      "Epoch  7 Data Point  26000 total loss 403.202 accuracy 0.995\n",
      "Epoch  7 Data Point  27000 total loss 417.978 accuracy 0.995\n",
      "Epoch  7 Data Point  28000 total loss 436.016 accuracy 0.995\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72586   661]\n",
      " [ 2422   302]]\n",
      "Finished Epoch  7 total loss 444.161 accuracy 0.995 validation f1 0.164\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947]\n",
      "Number of skipped points is  1\n",
      "Epoch  8 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  8 Data Point  1000 total loss 16.240 accuracy 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 Data Point  2000 total loss 29.972 accuracy 0.994\n",
      "Epoch  8 Data Point  3000 total loss 42.981 accuracy 0.995\n",
      "Epoch  8 Data Point  4000 total loss 57.310 accuracy 0.995\n",
      "Epoch  8 Data Point  5000 total loss 73.537 accuracy 0.994\n",
      "Epoch  8 Data Point  6000 total loss 86.718 accuracy 0.995\n",
      "Epoch  8 Data Point  7000 total loss 103.527 accuracy 0.994\n",
      "Epoch  8 Data Point  8000 total loss 122.126 accuracy 0.994\n",
      "Epoch  8 Data Point  9000 total loss 136.040 accuracy 0.994\n",
      "Epoch  8 Data Point  10000 total loss 150.266 accuracy 0.994\n",
      "Epoch  8 Data Point  11000 total loss 164.299 accuracy 0.995\n",
      "Epoch  8 Data Point  12000 total loss 179.033 accuracy 0.995\n",
      "Epoch  8 Data Point  13000 total loss 194.734 accuracy 0.995\n",
      "Epoch  8 Data Point  14000 total loss 204.494 accuracy 0.995\n",
      "Epoch  8 Data Point  15000 total loss 218.197 accuracy 0.995\n",
      "Epoch  8 Data Point  16000 total loss 230.096 accuracy 0.995\n",
      "Epoch  8 Data Point  17000 total loss 244.806 accuracy 0.995\n",
      "Epoch  8 Data Point  18000 total loss 258.956 accuracy 0.995\n",
      "Epoch  8 Data Point  19000 total loss 273.712 accuracy 0.995\n",
      "Epoch  8 Data Point  20000 total loss 291.522 accuracy 0.995\n",
      "Epoch  8 Data Point  21000 total loss 305.994 accuracy 0.995\n",
      "Epoch  8 Data Point  22000 total loss 318.030 accuracy 0.995\n",
      "Epoch  8 Data Point  23000 total loss 332.901 accuracy 0.995\n",
      "Epoch  8 Data Point  24000 total loss 347.443 accuracy 0.995\n",
      "Epoch  8 Data Point  25000 total loss 363.282 accuracy 0.995\n",
      "Epoch  8 Data Point  26000 total loss 380.535 accuracy 0.995\n",
      "Epoch  8 Data Point  27000 total loss 393.732 accuracy 0.995\n",
      "Epoch  8 Data Point  28000 total loss 407.383 accuracy 0.995\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73173    74]\n",
      " [ 2533   191]]\n",
      "Finished Epoch  8 total loss 416.407 accuracy 0.995 validation f1 0.128\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047]\n",
      "Number of skipped points is  1\n",
      "Epoch  9 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  9 Data Point  1000 total loss 11.054 accuracy 0.996\n",
      "Epoch  9 Data Point  2000 total loss 26.005 accuracy 0.995\n",
      "Epoch  9 Data Point  3000 total loss 40.101 accuracy 0.995\n",
      "Epoch  9 Data Point  4000 total loss 54.203 accuracy 0.995\n",
      "Epoch  9 Data Point  5000 total loss 65.914 accuracy 0.995\n",
      "Epoch  9 Data Point  6000 total loss 80.257 accuracy 0.995\n",
      "Epoch  9 Data Point  7000 total loss 93.292 accuracy 0.995\n",
      "Epoch  9 Data Point  8000 total loss 107.333 accuracy 0.995\n",
      "Epoch  9 Data Point  9000 total loss 120.055 accuracy 0.995\n",
      "Epoch  9 Data Point  10000 total loss 130.552 accuracy 0.995\n",
      "Epoch  9 Data Point  11000 total loss 147.229 accuracy 0.995\n",
      "Epoch  9 Data Point  12000 total loss 162.151 accuracy 0.995\n",
      "Epoch  9 Data Point  13000 total loss 174.936 accuracy 0.995\n",
      "Epoch  9 Data Point  14000 total loss 191.425 accuracy 0.995\n",
      "Epoch  9 Data Point  15000 total loss 207.086 accuracy 0.995\n",
      "Epoch  9 Data Point  16000 total loss 222.542 accuracy 0.995\n",
      "Epoch  9 Data Point  17000 total loss 233.174 accuracy 0.995\n",
      "Epoch  9 Data Point  18000 total loss 249.989 accuracy 0.995\n",
      "Epoch  9 Data Point  19000 total loss 263.894 accuracy 0.995\n",
      "Epoch  9 Data Point  20000 total loss 277.837 accuracy 0.995\n",
      "Epoch  9 Data Point  21000 total loss 289.863 accuracy 0.995\n",
      "Epoch  9 Data Point  22000 total loss 304.688 accuracy 0.995\n",
      "Epoch  9 Data Point  23000 total loss 317.742 accuracy 0.995\n",
      "Epoch  9 Data Point  24000 total loss 332.390 accuracy 0.995\n",
      "Epoch  9 Data Point  25000 total loss 344.647 accuracy 0.995\n",
      "Epoch  9 Data Point  26000 total loss 359.829 accuracy 0.995\n",
      "Epoch  9 Data Point  27000 total loss 375.360 accuracy 0.995\n",
      "Epoch  9 Data Point  28000 total loss 389.450 accuracy 0.995\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72701   546]\n",
      " [ 2306   418]]\n",
      "Finished Epoch  9 total loss 395.626 accuracy 0.995 validation f1 0.227\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  10 Data Point  0 total loss 0.004 accuracy 1.000\n",
      "Epoch  10 Data Point  1000 total loss 12.265 accuracy 0.996\n",
      "Epoch  10 Data Point  2000 total loss 25.919 accuracy 0.996\n",
      "Epoch  10 Data Point  3000 total loss 37.327 accuracy 0.996\n",
      "Epoch  10 Data Point  4000 total loss 47.922 accuracy 0.996\n",
      "Epoch  10 Data Point  5000 total loss 60.294 accuracy 0.996\n",
      "Epoch  10 Data Point  6000 total loss 75.121 accuracy 0.996\n",
      "Epoch  10 Data Point  7000 total loss 89.577 accuracy 0.996\n",
      "Epoch  10 Data Point  8000 total loss 100.321 accuracy 0.996\n",
      "Epoch  10 Data Point  9000 total loss 114.349 accuracy 0.996\n",
      "Epoch  10 Data Point  10000 total loss 128.446 accuracy 0.995\n",
      "Epoch  10 Data Point  11000 total loss 141.225 accuracy 0.995\n",
      "Epoch  10 Data Point  12000 total loss 153.299 accuracy 0.995\n",
      "Epoch  10 Data Point  13000 total loss 167.258 accuracy 0.995\n",
      "Epoch  10 Data Point  14000 total loss 179.590 accuracy 0.995\n",
      "Epoch  10 Data Point  15000 total loss 191.844 accuracy 0.995\n",
      "Epoch  10 Data Point  16000 total loss 206.982 accuracy 0.995\n",
      "Epoch  10 Data Point  17000 total loss 218.333 accuracy 0.995\n",
      "Epoch  10 Data Point  18000 total loss 231.114 accuracy 0.995\n",
      "Epoch  10 Data Point  19000 total loss 245.455 accuracy 0.995\n",
      "Epoch  10 Data Point  20000 total loss 260.905 accuracy 0.995\n",
      "Epoch  10 Data Point  21000 total loss 274.447 accuracy 0.995\n",
      "Epoch  10 Data Point  22000 total loss 290.248 accuracy 0.995\n",
      "Epoch  10 Data Point  23000 total loss 303.570 accuracy 0.995\n",
      "Epoch  10 Data Point  24000 total loss 314.321 accuracy 0.995\n",
      "Epoch  10 Data Point  25000 total loss 326.810 accuracy 0.995\n",
      "Epoch  10 Data Point  26000 total loss 337.206 accuracy 0.995\n",
      "Epoch  10 Data Point  27000 total loss 353.393 accuracy 0.995\n",
      "Epoch  10 Data Point  28000 total loss 364.725 accuracy 0.995\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72975   272]\n",
      " [ 2434   290]]\n",
      "Finished Epoch  10 total loss 371.036 accuracy 0.995 validation f1 0.177\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053]\n",
      "Number of skipped points is  1\n",
      "Epoch  11 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  11 Data Point  1000 total loss 13.712 accuracy 0.995\n",
      "Epoch  11 Data Point  2000 total loss 24.919 accuracy 0.996\n",
      "Epoch  11 Data Point  3000 total loss 34.657 accuracy 0.996\n",
      "Epoch  11 Data Point  4000 total loss 45.336 accuracy 0.996\n",
      "Epoch  11 Data Point  5000 total loss 59.203 accuracy 0.996\n",
      "Epoch  11 Data Point  6000 total loss 73.036 accuracy 0.996\n",
      "Epoch  11 Data Point  7000 total loss 86.705 accuracy 0.996\n",
      "Epoch  11 Data Point  8000 total loss 100.884 accuracy 0.995\n",
      "Epoch  11 Data Point  9000 total loss 110.431 accuracy 0.996\n",
      "Epoch  11 Data Point  10000 total loss 121.100 accuracy 0.996\n",
      "Epoch  11 Data Point  11000 total loss 136.987 accuracy 0.996\n",
      "Epoch  11 Data Point  12000 total loss 148.897 accuracy 0.995\n",
      "Epoch  11 Data Point  13000 total loss 163.628 accuracy 0.995\n",
      "Epoch  11 Data Point  14000 total loss 177.324 accuracy 0.995\n",
      "Epoch  11 Data Point  15000 total loss 189.127 accuracy 0.995\n",
      "Epoch  11 Data Point  16000 total loss 200.657 accuracy 0.995\n",
      "Epoch  11 Data Point  17000 total loss 215.582 accuracy 0.995\n",
      "Epoch  11 Data Point  18000 total loss 227.219 accuracy 0.995\n",
      "Epoch  11 Data Point  19000 total loss 238.828 accuracy 0.995\n",
      "Epoch  11 Data Point  20000 total loss 252.529 accuracy 0.995\n",
      "Epoch  11 Data Point  21000 total loss 265.567 accuracy 0.995\n",
      "Epoch  11 Data Point  22000 total loss 275.954 accuracy 0.996\n",
      "Epoch  11 Data Point  23000 total loss 291.308 accuracy 0.995\n",
      "Epoch  11 Data Point  24000 total loss 305.158 accuracy 0.995\n",
      "Epoch  11 Data Point  25000 total loss 318.799 accuracy 0.995\n",
      "Epoch  11 Data Point  26000 total loss 331.942 accuracy 0.995\n",
      "Epoch  11 Data Point  27000 total loss 347.437 accuracy 0.995\n",
      "Epoch  11 Data Point  28000 total loss 357.631 accuracy 0.995\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72938   309]\n",
      " [ 2401   323]]\n",
      "Finished Epoch  11 total loss 364.587 accuracy 0.995 validation f1 0.192\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12 Data Point  0 total loss 0.001 accuracy 1.000\n",
      "Epoch  12 Data Point  1000 total loss 9.848 accuracy 0.997\n",
      "Epoch  12 Data Point  2000 total loss 21.774 accuracy 0.996\n",
      "Epoch  12 Data Point  3000 total loss 33.887 accuracy 0.996\n",
      "Epoch  12 Data Point  4000 total loss 46.890 accuracy 0.996\n",
      "Epoch  12 Data Point  5000 total loss 57.930 accuracy 0.996\n",
      "Epoch  12 Data Point  6000 total loss 69.960 accuracy 0.996\n",
      "Epoch  12 Data Point  7000 total loss 80.412 accuracy 0.996\n",
      "Epoch  12 Data Point  8000 total loss 94.280 accuracy 0.996\n",
      "Epoch  12 Data Point  9000 total loss 106.016 accuracy 0.996\n",
      "Epoch  12 Data Point  10000 total loss 117.744 accuracy 0.996\n",
      "Epoch  12 Data Point  11000 total loss 129.893 accuracy 0.996\n",
      "Epoch  12 Data Point  12000 total loss 142.177 accuracy 0.996\n",
      "Epoch  12 Data Point  13000 total loss 157.108 accuracy 0.996\n",
      "Epoch  12 Data Point  14000 total loss 167.830 accuracy 0.996\n",
      "Epoch  12 Data Point  15000 total loss 179.160 accuracy 0.996\n",
      "Epoch  12 Data Point  16000 total loss 191.549 accuracy 0.996\n",
      "Epoch  12 Data Point  17000 total loss 201.052 accuracy 0.996\n",
      "Epoch  12 Data Point  18000 total loss 213.092 accuracy 0.996\n",
      "Epoch  12 Data Point  19000 total loss 226.426 accuracy 0.996\n",
      "Epoch  12 Data Point  20000 total loss 239.055 accuracy 0.996\n",
      "Epoch  12 Data Point  21000 total loss 249.446 accuracy 0.996\n",
      "Epoch  12 Data Point  22000 total loss 258.474 accuracy 0.996\n",
      "Epoch  12 Data Point  23000 total loss 268.534 accuracy 0.996\n",
      "Epoch  12 Data Point  24000 total loss 279.458 accuracy 0.996\n",
      "Epoch  12 Data Point  25000 total loss 291.826 accuracy 0.996\n",
      "Epoch  12 Data Point  26000 total loss 300.408 accuracy 0.996\n",
      "Epoch  12 Data Point  27000 total loss 316.070 accuracy 0.996\n",
      "Epoch  12 Data Point  28000 total loss 325.095 accuracy 0.996\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73172    75]\n",
      " [ 2415   309]]\n",
      "Finished Epoch  12 total loss 332.060 accuracy 0.996 validation f1 0.199\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508, 0.1988416988416988]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  13 Data Point  0 total loss 0.002 accuracy 1.000\n",
      "Epoch  13 Data Point  1000 total loss 13.036 accuracy 0.995\n",
      "Epoch  13 Data Point  2000 total loss 24.420 accuracy 0.995\n",
      "Epoch  13 Data Point  3000 total loss 38.072 accuracy 0.995\n",
      "Epoch  13 Data Point  4000 total loss 48.496 accuracy 0.996\n",
      "Epoch  13 Data Point  5000 total loss 61.035 accuracy 0.995\n",
      "Epoch  13 Data Point  6000 total loss 70.408 accuracy 0.996\n",
      "Epoch  13 Data Point  7000 total loss 86.217 accuracy 0.995\n",
      "Epoch  13 Data Point  8000 total loss 100.944 accuracy 0.995\n",
      "Epoch  13 Data Point  9000 total loss 112.894 accuracy 0.995\n",
      "Epoch  13 Data Point  10000 total loss 123.649 accuracy 0.995\n",
      "Epoch  13 Data Point  11000 total loss 132.407 accuracy 0.996\n",
      "Epoch  13 Data Point  12000 total loss 144.737 accuracy 0.996\n",
      "Epoch  13 Data Point  13000 total loss 156.066 accuracy 0.996\n",
      "Epoch  13 Data Point  14000 total loss 167.178 accuracy 0.996\n",
      "Epoch  13 Data Point  15000 total loss 177.607 accuracy 0.996\n",
      "Epoch  13 Data Point  16000 total loss 188.379 accuracy 0.996\n",
      "Epoch  13 Data Point  17000 total loss 197.717 accuracy 0.996\n",
      "Epoch  13 Data Point  18000 total loss 208.985 accuracy 0.996\n",
      "Epoch  13 Data Point  19000 total loss 219.366 accuracy 0.996\n",
      "Epoch  13 Data Point  20000 total loss 232.507 accuracy 0.996\n",
      "Epoch  13 Data Point  21000 total loss 244.308 accuracy 0.996\n",
      "Epoch  13 Data Point  22000 total loss 255.789 accuracy 0.996\n",
      "Epoch  13 Data Point  23000 total loss 266.467 accuracy 0.996\n",
      "Epoch  13 Data Point  24000 total loss 276.932 accuracy 0.996\n",
      "Epoch  13 Data Point  25000 total loss 287.745 accuracy 0.996\n",
      "Epoch  13 Data Point  26000 total loss 298.791 accuracy 0.996\n",
      "Epoch  13 Data Point  27000 total loss 310.421 accuracy 0.996\n",
      "Epoch  13 Data Point  28000 total loss 321.816 accuracy 0.996\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73160    87]\n",
      " [ 2506   218]]\n",
      "Finished Epoch  13 total loss 326.905 accuracy 0.996 validation f1 0.144\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508, 0.1988416988416988, 0.14394189501485638]\n",
      "Number of skipped points is  1\n",
      "Epoch  14 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  14 Data Point  1000 total loss 11.032 accuracy 0.996\n",
      "Epoch  14 Data Point  2000 total loss 26.707 accuracy 0.996\n",
      "Epoch  14 Data Point  3000 total loss 35.451 accuracy 0.996\n",
      "Epoch  14 Data Point  4000 total loss 43.457 accuracy 0.996\n",
      "Epoch  14 Data Point  5000 total loss 54.050 accuracy 0.996\n",
      "Epoch  14 Data Point  6000 total loss 62.837 accuracy 0.996\n",
      "Epoch  14 Data Point  7000 total loss 73.901 accuracy 0.996\n",
      "Epoch  14 Data Point  8000 total loss 85.632 accuracy 0.996\n",
      "Epoch  14 Data Point  9000 total loss 95.114 accuracy 0.996\n",
      "Epoch  14 Data Point  10000 total loss 104.209 accuracy 0.996\n",
      "Epoch  14 Data Point  11000 total loss 112.420 accuracy 0.996\n",
      "Epoch  14 Data Point  12000 total loss 120.656 accuracy 0.996\n",
      "Epoch  14 Data Point  13000 total loss 131.030 accuracy 0.996\n",
      "Epoch  14 Data Point  14000 total loss 143.201 accuracy 0.996\n",
      "Epoch  14 Data Point  15000 total loss 153.890 accuracy 0.996\n",
      "Epoch  14 Data Point  16000 total loss 165.243 accuracy 0.996\n",
      "Epoch  14 Data Point  17000 total loss 173.928 accuracy 0.996\n",
      "Epoch  14 Data Point  18000 total loss 185.647 accuracy 0.996\n",
      "Epoch  14 Data Point  19000 total loss 197.846 accuracy 0.996\n",
      "Epoch  14 Data Point  20000 total loss 210.726 accuracy 0.996\n",
      "Epoch  14 Data Point  21000 total loss 222.153 accuracy 0.996\n",
      "Epoch  14 Data Point  22000 total loss 230.837 accuracy 0.996\n",
      "Epoch  14 Data Point  23000 total loss 244.165 accuracy 0.996\n",
      "Epoch  14 Data Point  24000 total loss 256.434 accuracy 0.996\n",
      "Epoch  14 Data Point  25000 total loss 267.132 accuracy 0.996\n",
      "Epoch  14 Data Point  26000 total loss 280.127 accuracy 0.996\n",
      "Epoch  14 Data Point  27000 total loss 289.925 accuracy 0.996\n",
      "Epoch  14 Data Point  28000 total loss 304.550 accuracy 0.996\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[73106   141]\n",
      " [ 2533   191]]\n",
      "Finished Epoch  14 total loss 309.724 accuracy 0.996 validation f1 0.125\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508, 0.1988416988416988, 0.14394189501485638, 0.125]\n",
      "Number of skipped points is  1\n",
      "Epoch  15 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  15 Data Point  1000 total loss 11.211 accuracy 0.996\n",
      "Epoch  15 Data Point  2000 total loss 19.635 accuracy 0.996\n",
      "Epoch  15 Data Point  3000 total loss 29.681 accuracy 0.996\n",
      "Epoch  15 Data Point  4000 total loss 39.644 accuracy 0.996\n",
      "Epoch  15 Data Point  5000 total loss 46.926 accuracy 0.997\n",
      "Epoch  15 Data Point  6000 total loss 58.384 accuracy 0.996\n",
      "Epoch  15 Data Point  7000 total loss 66.565 accuracy 0.996\n",
      "Epoch  15 Data Point  8000 total loss 73.310 accuracy 0.997\n",
      "Epoch  15 Data Point  9000 total loss 81.878 accuracy 0.997\n",
      "Epoch  15 Data Point  10000 total loss 92.809 accuracy 0.997\n",
      "Epoch  15 Data Point  11000 total loss 104.608 accuracy 0.997\n",
      "Epoch  15 Data Point  12000 total loss 113.283 accuracy 0.996\n",
      "Epoch  15 Data Point  13000 total loss 121.871 accuracy 0.996\n",
      "Epoch  15 Data Point  14000 total loss 131.123 accuracy 0.996\n",
      "Epoch  15 Data Point  15000 total loss 141.425 accuracy 0.996\n",
      "Epoch  15 Data Point  16000 total loss 152.436 accuracy 0.996\n",
      "Epoch  15 Data Point  17000 total loss 162.721 accuracy 0.996\n",
      "Epoch  15 Data Point  18000 total loss 176.878 accuracy 0.996\n",
      "Epoch  15 Data Point  19000 total loss 188.810 accuracy 0.996\n",
      "Epoch  15 Data Point  20000 total loss 199.329 accuracy 0.996\n",
      "Epoch  15 Data Point  21000 total loss 207.568 accuracy 0.996\n",
      "Epoch  15 Data Point  22000 total loss 219.587 accuracy 0.996\n",
      "Epoch  15 Data Point  23000 total loss 233.123 accuracy 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15 Data Point  24000 total loss 243.335 accuracy 0.996\n",
      "Epoch  15 Data Point  25000 total loss 255.530 accuracy 0.996\n",
      "Epoch  15 Data Point  26000 total loss 263.619 accuracy 0.996\n",
      "Epoch  15 Data Point  27000 total loss 273.416 accuracy 0.996\n",
      "Epoch  15 Data Point  28000 total loss 283.532 accuracy 0.996\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72733   514]\n",
      " [ 2415   309]]\n",
      "Finished Epoch  15 total loss 290.035 accuracy 0.996 validation f1 0.174\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508, 0.1988416988416988, 0.14394189501485638, 0.125, 0.17423174513673526]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  16 Data Point  0 total loss 0.010 accuracy 1.000\n",
      "Epoch  16 Data Point  1000 total loss 8.898 accuracy 0.996\n",
      "Epoch  16 Data Point  2000 total loss 17.584 accuracy 0.997\n",
      "Epoch  16 Data Point  3000 total loss 26.043 accuracy 0.997\n",
      "Epoch  16 Data Point  4000 total loss 38.157 accuracy 0.997\n",
      "Epoch  16 Data Point  5000 total loss 45.711 accuracy 0.997\n",
      "Epoch  16 Data Point  6000 total loss 55.821 accuracy 0.997\n",
      "Epoch  16 Data Point  7000 total loss 63.694 accuracy 0.997\n",
      "Epoch  16 Data Point  8000 total loss 73.071 accuracy 0.997\n",
      "Epoch  16 Data Point  9000 total loss 84.664 accuracy 0.997\n",
      "Epoch  16 Data Point  10000 total loss 94.483 accuracy 0.997\n",
      "Epoch  16 Data Point  11000 total loss 104.550 accuracy 0.997\n",
      "Epoch  16 Data Point  12000 total loss 116.438 accuracy 0.997\n",
      "Epoch  16 Data Point  13000 total loss 126.782 accuracy 0.997\n",
      "Epoch  16 Data Point  14000 total loss 136.128 accuracy 0.997\n",
      "Epoch  16 Data Point  15000 total loss 147.208 accuracy 0.997\n",
      "Epoch  16 Data Point  16000 total loss 155.131 accuracy 0.997\n",
      "Epoch  16 Data Point  17000 total loss 166.492 accuracy 0.996\n",
      "Epoch  16 Data Point  18000 total loss 175.962 accuracy 0.996\n",
      "Epoch  16 Data Point  19000 total loss 183.904 accuracy 0.996\n",
      "Epoch  16 Data Point  20000 total loss 193.971 accuracy 0.997\n",
      "Epoch  16 Data Point  21000 total loss 204.153 accuracy 0.997\n",
      "Epoch  16 Data Point  22000 total loss 214.401 accuracy 0.997\n",
      "Epoch  16 Data Point  23000 total loss 223.715 accuracy 0.997\n",
      "Epoch  16 Data Point  24000 total loss 234.345 accuracy 0.997\n",
      "Epoch  16 Data Point  25000 total loss 247.121 accuracy 0.996\n",
      "Epoch  16 Data Point  26000 total loss 255.671 accuracy 0.997\n",
      "Epoch  16 Data Point  27000 total loss 267.418 accuracy 0.996\n",
      "Epoch  16 Data Point  28000 total loss 278.379 accuracy 0.996\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72493   754]\n",
      " [ 2300   424]]\n",
      "Finished Epoch  16 total loss 282.948 accuracy 0.996 validation f1 0.217\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508, 0.1988416988416988, 0.14394189501485638, 0.125, 0.17423174513673526, 0.21732444900051257]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  17 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  17 Data Point  1000 total loss 7.145 accuracy 0.998\n",
      "Epoch  17 Data Point  2000 total loss 18.948 accuracy 0.997\n",
      "Epoch  17 Data Point  3000 total loss 25.350 accuracy 0.997\n",
      "Epoch  17 Data Point  4000 total loss 36.699 accuracy 0.997\n",
      "Epoch  17 Data Point  5000 total loss 44.303 accuracy 0.997\n",
      "Epoch  17 Data Point  6000 total loss 54.136 accuracy 0.997\n",
      "Epoch  17 Data Point  7000 total loss 64.342 accuracy 0.997\n",
      "Epoch  17 Data Point  8000 total loss 73.916 accuracy 0.997\n",
      "Epoch  17 Data Point  9000 total loss 83.042 accuracy 0.997\n",
      "Epoch  17 Data Point  10000 total loss 91.113 accuracy 0.997\n",
      "Epoch  17 Data Point  11000 total loss 103.076 accuracy 0.997\n",
      "Epoch  17 Data Point  12000 total loss 110.656 accuracy 0.997\n",
      "Epoch  17 Data Point  13000 total loss 118.741 accuracy 0.997\n",
      "Epoch  17 Data Point  14000 total loss 127.429 accuracy 0.997\n",
      "Epoch  17 Data Point  15000 total loss 136.108 accuracy 0.997\n",
      "Epoch  17 Data Point  16000 total loss 147.983 accuracy 0.997\n",
      "Epoch  17 Data Point  17000 total loss 158.447 accuracy 0.997\n",
      "Epoch  17 Data Point  18000 total loss 166.030 accuracy 0.997\n",
      "Epoch  17 Data Point  19000 total loss 177.132 accuracy 0.997\n",
      "Epoch  17 Data Point  20000 total loss 185.110 accuracy 0.997\n",
      "Epoch  17 Data Point  21000 total loss 195.529 accuracy 0.997\n",
      "Epoch  17 Data Point  22000 total loss 202.212 accuracy 0.997\n",
      "Epoch  17 Data Point  23000 total loss 210.164 accuracy 0.997\n",
      "Epoch  17 Data Point  24000 total loss 221.205 accuracy 0.997\n",
      "Epoch  17 Data Point  25000 total loss 228.111 accuracy 0.997\n",
      "Epoch  17 Data Point  26000 total loss 238.163 accuracy 0.997\n",
      "Epoch  17 Data Point  27000 total loss 248.018 accuracy 0.997\n",
      "Epoch  17 Data Point  28000 total loss 257.257 accuracy 0.997\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72926   321]\n",
      " [ 2340   384]]\n",
      "Finished Epoch  17 total loss 261.089 accuracy 0.997 validation f1 0.224\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508, 0.1988416988416988, 0.14394189501485638, 0.125, 0.17423174513673526, 0.21732444900051257, 0.2239720034995626]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "Epoch  18 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  18 Data Point  1000 total loss 10.603 accuracy 0.996\n",
      "Epoch  18 Data Point  2000 total loss 17.888 accuracy 0.997\n",
      "Epoch  18 Data Point  3000 total loss 30.215 accuracy 0.997\n",
      "Epoch  18 Data Point  4000 total loss 39.947 accuracy 0.997\n",
      "Epoch  18 Data Point  5000 total loss 48.176 accuracy 0.997\n",
      "Epoch  18 Data Point  6000 total loss 55.616 accuracy 0.997\n",
      "Epoch  18 Data Point  7000 total loss 63.152 accuracy 0.997\n",
      "Epoch  18 Data Point  8000 total loss 70.459 accuracy 0.997\n",
      "Epoch  18 Data Point  9000 total loss 79.326 accuracy 0.997\n",
      "Epoch  18 Data Point  10000 total loss 86.597 accuracy 0.997\n",
      "Epoch  18 Data Point  11000 total loss 95.745 accuracy 0.997\n",
      "Epoch  18 Data Point  12000 total loss 105.581 accuracy 0.997\n",
      "Epoch  18 Data Point  13000 total loss 115.567 accuracy 0.997\n",
      "Epoch  18 Data Point  14000 total loss 124.858 accuracy 0.997\n",
      "Epoch  18 Data Point  15000 total loss 131.713 accuracy 0.997\n",
      "Epoch  18 Data Point  16000 total loss 140.986 accuracy 0.997\n",
      "Epoch  18 Data Point  17000 total loss 149.078 accuracy 0.997\n",
      "Epoch  18 Data Point  18000 total loss 160.262 accuracy 0.997\n",
      "Epoch  18 Data Point  19000 total loss 166.915 accuracy 0.997\n",
      "Epoch  18 Data Point  20000 total loss 176.574 accuracy 0.997\n",
      "Epoch  18 Data Point  21000 total loss 182.867 accuracy 0.997\n",
      "Epoch  18 Data Point  22000 total loss 191.599 accuracy 0.997\n",
      "Epoch  18 Data Point  23000 total loss 199.072 accuracy 0.997\n",
      "Epoch  18 Data Point  24000 total loss 209.288 accuracy 0.997\n",
      "Epoch  18 Data Point  25000 total loss 219.277 accuracy 0.997\n",
      "Epoch  18 Data Point  26000 total loss 229.101 accuracy 0.997\n",
      "Epoch  18 Data Point  27000 total loss 241.628 accuracy 0.997\n",
      "Epoch  18 Data Point  28000 total loss 249.414 accuracy 0.997\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72549   698]\n",
      " [ 2436   288]]\n",
      "Finished Epoch  18 total loss 254.768 accuracy 0.997 validation f1 0.155\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508, 0.1988416988416988, 0.14394189501485638, 0.125, 0.17423174513673526, 0.21732444900051257, 0.2239720034995626, 0.15525606469002695]\n",
      "Number of skipped points is  1\n",
      "Epoch  19 Data Point  0 total loss 0.000 accuracy 1.000\n",
      "Epoch  19 Data Point  1000 total loss 6.484 accuracy 0.998\n",
      "Epoch  19 Data Point  2000 total loss 13.800 accuracy 0.998\n",
      "Epoch  19 Data Point  3000 total loss 22.937 accuracy 0.997\n",
      "Epoch  19 Data Point  4000 total loss 29.968 accuracy 0.997\n",
      "Epoch  19 Data Point  5000 total loss 37.765 accuracy 0.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19 Data Point  6000 total loss 45.818 accuracy 0.997\n",
      "Epoch  19 Data Point  7000 total loss 57.507 accuracy 0.997\n",
      "Epoch  19 Data Point  8000 total loss 63.965 accuracy 0.997\n",
      "Epoch  19 Data Point  9000 total loss 70.779 accuracy 0.997\n",
      "Epoch  19 Data Point  10000 total loss 78.179 accuracy 0.997\n",
      "Epoch  19 Data Point  11000 total loss 88.130 accuracy 0.997\n",
      "Epoch  19 Data Point  12000 total loss 95.633 accuracy 0.997\n",
      "Epoch  19 Data Point  13000 total loss 103.132 accuracy 0.997\n",
      "Epoch  19 Data Point  14000 total loss 110.533 accuracy 0.997\n",
      "Epoch  19 Data Point  15000 total loss 119.738 accuracy 0.997\n",
      "Epoch  19 Data Point  16000 total loss 126.868 accuracy 0.997\n",
      "Epoch  19 Data Point  17000 total loss 135.069 accuracy 0.997\n",
      "Epoch  19 Data Point  18000 total loss 145.976 accuracy 0.997\n",
      "Epoch  19 Data Point  19000 total loss 155.458 accuracy 0.997\n",
      "Epoch  19 Data Point  20000 total loss 164.183 accuracy 0.997\n",
      "Epoch  19 Data Point  21000 total loss 173.032 accuracy 0.997\n",
      "Epoch  19 Data Point  22000 total loss 181.255 accuracy 0.997\n",
      "Epoch  19 Data Point  23000 total loss 189.966 accuracy 0.997\n",
      "Epoch  19 Data Point  24000 total loss 197.784 accuracy 0.997\n",
      "Epoch  19 Data Point  25000 total loss 205.152 accuracy 0.997\n",
      "Epoch  19 Data Point  26000 total loss 214.677 accuracy 0.997\n",
      "Epoch  19 Data Point  27000 total loss 221.215 accuracy 0.997\n",
      "Epoch  19 Data Point  28000 total loss 231.402 accuracy 0.997\n",
      "I am passing\n",
      "The confusion matrix is: \n",
      " [[72977   270]\n",
      " [ 2404   320]]\n",
      "Finished Epoch  19 total loss 238.625 accuracy 0.997 validation f1 0.193\n",
      "[0, 0, 0, 0.10595115239078087, 0.24969097651421504, 0.17528830313014826, 0.09192200557103064, 0.18015665796344646, 0.24906367041198504, 0.28917853895119733, 0.16381882289123947, 0.12780194044831047, 0.22668112798264645, 0.17650639074863053, 0.1924910607866508, 0.1988416988416988, 0.14394189501485638, 0.125, 0.17423174513673526, 0.21732444900051257, 0.2239720034995626, 0.15525606469002695, 0.19312009656004828]\n",
      "Number of skipped points is  1\n",
      "... saving checkpoint ...\n",
      "The amount of time for training is:  14418.08671593666\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# network.load_checkpoint(filename=\"cnn_history/CNN_best_V3\")\n",
    "network._train()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"The amount of time for training is: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading checkpoint ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidhartkrishnan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is: \n",
      " [[73149    98]\n",
      " [ 2247   477]]\n",
      "0.28917853895119733\n"
     ]
    }
   ],
   "source": [
    "network.load_checkpoint(filename=\"cnn_history/endpt_cnn/CNN_best_V5\")\n",
    "network._val()\n",
    "print(network.val_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading checkpoint ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidhartkrishnan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is: \n",
      " [[72858   343]\n",
      " [  135  2632]]\n",
      "The f1 score is 0.9167537443399513\n",
      "Total loss 179.281 accuracy 0.994\n",
      "Number of skipped points is  1\n"
     ]
    }
   ],
   "source": [
    "network.load_checkpoint(filename=\"cnn_history/endpt_cnn/CNN_best_V5\")\n",
    "ep_acc = network._test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937078770008425"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ep_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(network.acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading checkpoint ...\n",
      "25635 25635\n"
     ]
    }
   ],
   "source": [
    "# num_images = 10000\n",
    "images, labels, filenames = load_images_from_folder(\"test_mini_images\")\n",
    "network.load_checkpoint(filename=\"cnn_history/endpt_cnn/CNN_best_V5\")\n",
    "print(len(images), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25635, 1, 25, 25])\n"
     ]
    }
   ],
   "source": [
    "images = T.tensor(images, dtype = T.float)\n",
    "images = T.reshape(images, (len(images),1,25,25))\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidhartkrishnan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25635, 2])\n",
      "Classes is  25635\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "# network.load_checkpoint(filename=\"cnn_history/CNN_best_V4\")\n",
    "prediction = network.forward(images)\n",
    "prediction = F.softmax(prediction, dim=1) # the softmax is so that we get a probabilities over the classes \n",
    "print(prediction.size())\n",
    "classes = T.argmax(prediction, dim=1)\n",
    "# classes = [int((p[1] > 0.8).item()) for p in prediction]\n",
    "print(\"Classes is \", len(classes))\n",
    "counter = 0\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] != classes[i]:\n",
    "#         print(classes[i], i)\n",
    "        counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(205)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show(image):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "\n",
    "img = cv2.imread('test_images/test4.jpeg')\n",
    "print(sum(classes))\n",
    "for i in range(len(images)):\n",
    "    if classes[i]:\n",
    "#         print(filenames[i])\n",
    "        coords = [int(filenames[i].split(\"_\")[0]), int(filenames[i].split(\"_\")[1])]\n",
    "        for x in range(coords[0], coords[0] + 25):\n",
    "#         for x in range(coords[0] - 12, coords[0] + 38):\n",
    "            for y in [coords[1], coords[1] + 25]:\n",
    "#             for y in [coords[1] - 12, coords[1] + 38]:\n",
    "                img[x][y] = (255,0,0)\n",
    "        for y in range(coords[1], coords[1] + 25):\n",
    "#         for y in range(coords[1] - 12, coords[1] + 38):\n",
    "            for x in [coords[0], coords[0] + 25]:\n",
    "#             for x in [coords[0] - 12, coords[0] + 38]:\n",
    "                img[x][y] = (255,0,0)\n",
    "\n",
    "cv2.imwrite('boxed_images/boxed5.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels, filenames = load_images_from_folder(\"final_dataset\", num_images=10000)\n",
    "# for img in images:\n",
    "#     for i in range(len(img)):\n",
    "#         for j in range(len(img[i])):\n",
    "#             if img[i][j] > 25 and img[i][j] < 230:\n",
    "#                 print(img[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
